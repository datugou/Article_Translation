# 如何交付机器学习项目
_作者：[**Emmanuel Ameisen**](https://twitter.com/EmmanuelAmeisen)--Insight Data Science 的 AI 负责人、[**Adam Coates**](https://twitter.com/adampaulcoates)--Khosla Ventures 运营合伙人_  
_原文链接：<https://mlpowered.com/posts/how-to-deliver-on-machine-learning-projects/>_  
_2018 年 10 月 4 日  
`Machine Learning`

---
随着机器学习（ML）正在成为各行各业的重要组成部分，市场对机器学习工程师（MLE）的需求急剧增长。
MLE 将机器学习技能与软件工程知识结合起来，为给定的应用找到高性能的模型，并处理随之而来的项目实施问题--从搭建训练基础设施到模型的部署。
同时涌现了大量的在线资源，以培训工程师构建 ML 模型并解决遇到的各种软件工程挑战。
然而，新的 ML 团队最常见的障碍之一是，如何保证机器学习工程的开发进度。

这一挑战最紧迫的原因是，开发新 ML 模型的过程在一开始就具有高度的不确定性。
毕竟，很难知道一个模型在给定的训练运行结束时的性能如何，更不用说预测参数调整或建模选取可以带来怎样的性能提升。

许多类型的专业人士都面临着类似的情况：软件和业务开发人员、寻找产品与市场契合度的初创公司，或者是在有限信息下进行操纵的飞行员。
这些领域都有一种几乎通用的框架，以帮助他们的团队在不确定性中高效地工作：软件开发的“敏捷开发”，创业公司的“精益创业”，以及美国空军的“OODA Loop”。
MLE 也可以遵循类似的框架来应对不确定性，并快速交付优秀的产品。

## ML Engineering Loop（MLE Loop）
在这篇文章中，我们将描述 ML 的“OODA Loop”概念：**MLE Loop**，ML 工程师可以在其中进行迭代：
1. 分析
2. 方法选择
3. 实施
4. 衡量

以快速有效地发现最佳模型并适应未知的情况。
此外，我们为每一个阶段提供具体的提示，以及从整体上优化的建议。

<div align=center><img src="https://s1.ax1x.com/2020/11/09/BH8GkV.png"></div>
<div align=center><h6>MLE Loop</h6></div>

对于 ML 团队来说，成功往往意味着在给定的约束条件下交付一个高性能的模型--
例如，一个能达到高预测精度的模型，同时要受到内存使用、推理时间和公平性的约束。
**性能是由任何一个与你的最终产品的成功最相关的指标来定义的**，无论是准确性、速度、输出的多样性等。
为了简单起见，我们选择将“错误率”最小化作为下面的性能指标。

当你刚开始确定一个新项目的范围时，你应该准确定义成功标准，然后将其转化为模型指标。
**在产品方面**，一项服务需要达到什么样的性能水平才能满足用户使用？
例如，如果我们要在新闻平台上向个人用户推荐 5 篇文章，那么我们需要多少篇相关的文章，我们将如何定义相关性？
鉴于这个性能标准和你所掌握的数据，你能建立的最简单的模型是什么？

> 在产品方面，一个服务需要达到什么样的性能水平才能满足用户使用？

ML Engineering Loop 的目的是围绕开发过程建立一套固定的框架，从而简化决策过程，使其仅专注于最重要的后续步骤。
随着从业者经验的进步，这个过程就会变成第二天性，而不断增长的专业知识则可以毫不犹豫地在分析和实施之间快速转变。
也就是说，当不确定性增加时，这个框架对于即使是最有经验的工程师来说也是非常有价值的----例如，当一个模型意外地不能满足需求时，当团队的目标突然被改变时（例如，测试集被改变以反映产品需求的变化），或者当团队的进展在离最终目标不远处停滞不前时。

## 开始
为了引导 MLE Loop 能够正常循环，你应先实现一个最小可运行的框架，这里涉及的不确定性非常小。
通常我们希望尽快地“得到一个结果（不管结果是好还是坏）”----我们只需要建立一个足够小的系统，能让我们评估它的性能并开始迭代就可以了。
这通常意味着做到下面俩点就行：
1. 设置训练、验证和测试数据集
2. 让一个简单的模型正常运作

例如，如果我们要开发一个树木检测器来调查一个地区的树木种群，我们可能会使用类似 [Kaggle 竞赛](https://www.kaggle.com/c/inaturalist-challenge-at-fgvc-2017/data)中的现成数据作为训练集，以及人工收集标记的一组照片作为验证集和测试集。
然后，我们可以在原始像素上运行逻辑回归，或者在训练集的图像上运行一个预训练的网络（如 [ResNet](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)）。
这里的目标不是一次性解决项目，而是能让我们的迭代周期正常开展。
下面是一些小技巧来帮助你做到这一点。

### 小贴士：
关于一个好的测试集：
- 由于团队的目标是在测试集上取得好成绩，测试集实际上侧面反映了团队的目标。
因此，测试集应该反映产品或业务的需求。
例如，如果你正在构建一个从自拍中检测皮肤状况的 APP，你可以在任何图像集上进行训练，但要确保你的测试集包含一些像自拍光线不足、质量不佳等图像。
- 改变测试集会改变团队的目标，所以要尽早修正测试集，并且只有当项目、产品或业务目标的变化时，才去修改测试集。
- 争取让测试集和验证集足够大，这样你的性能指标才会足够准确，才能很好地区分不同模型之间的差异。
如果集子太小，你最终只能在嘈杂的结果上做出决策。
- 同样，对于验证集和测试集，您应选择尽可能实用的标签或注释。
一个标签错误的测试集就和一个错误的产品需求差不多。
- 了解人类在鉴别测试集时的表现，或者现有/竞争对手的系统的表现是很有帮助的。
你可以借助这些信息评价自己的模型表现如何，以及可能达到的最佳水平。
- 对于许多任务来说，达到与人类测试性能相当的水平通常是一个长期目标。
在任何情况下，最终的目标是使测试性能尽可能地接近我们假设的最佳性能。

关于验证集和训练集：

- 验证集是团队用于性能测试的代理，他们可以用来调整超参数。
因此，它应该来自与测试集相同的分布，但最好是来自不相干的用户/输入组，以避免数据内部隐藏信息的泄漏。
确保这一点的一个好方法是首先策划一个大的样本池，然后洗牌并在之后将它们分成开发集和测试集。
- 如果你认为生产环境中的数据会很嘈杂，请确保通过使用数据扩充或降级在训练集中解决噪声的问题。
你不能指望一个专门在高清图像上训练的模型能泛化到模糊的图像上。

一旦你有了最初的原型，你应该利用训练、验证和测试集来检查其性能。
这标志着你第一次循环之旅的结束。
总结一下测试的性能与可用产品所需性能之间的差距。
现在是时候开始迭代了!

## 分析
### 识别性能瓶颈
分析阶段就像医疗诊断一样：你配备了一套可以执行的诊断程序，你的目标是对限制你的模型性能的原因提出最有可能的诊断。
在实践中，可能会有许多不同的重叠问题导致当前的结果，但你的目标是先找到最明显的问题，以便迅速解决它们。
不要陷入对每个缺点都要全面理解的泥沼中----首要目标是了解目前最大的影响因素，因为许多较小的问题会随着你对模型的改进而改变甚至消失。

下面，我们列出了一套你将经常使用的常见诊断方法以及一些诊断结果。
并没有具体的方案指导你应该选择哪种诊断程序，但随着在 MLE Loop 中的工作，你可能会逐渐获一些直觉。

每个分析的一个好的起点是看你的训练、开发和测试性能。我们建议在每次实验结束时放上代码来做这件事，让自己习惯于每次都看这些数字。平均来说，我们会有：训练误差<=开发集误差<=测试集误差（如果每组数据遵循相同的分布）。利用上次实验中的训练、开发和测试错误率，你可以很快看到这些因素中的哪一个是目前的约束条件。例如，当训练误差和开发集误差之间的差距很小时，那么你的训练误差就代表了提高性能的瓶颈。

通过www.DeepL.com/Translator（免费版）翻译


## ~~章节题目~~
~~内容~~
<img src="https://s1.ax1x.com/2020/10/14/054e6e.png" alt="054e6e.png" border="0" />
<div align=center><img src="https://s1.ax1x.com/2020/10/14/054e6e.png"></div>
<div align=center><h6>在极端情况下，每个功能区/产品由7个人组成</h6></div>
---
[返回目录](https://github.com/datugou/Article_Translation/tree/master/LEARNING_data_science)
