# 软件 2.0
_作者：[**Andrej Karpathy**](https://medium.com/@karpathy)_  
_原文链接：<https://medium.com/@karpathy/software-2-0-a64152b37c35>_  
_2017 年 11 月 12 日_  
`machine learning` `software development` `AI`

---
我有时会看到人们将神经网络称为“机器学习工具箱中的一个工具”而已。
它们有一些优点和缺点，在这里或那里发挥作用，有时你可以用它们来赢得 Kaggle 比赛。
不幸的是，这种解释完全是只见树木，不见森林。
神经网络不仅仅是另一种分类器，它们代表了我们编写软件方式的根本开始发生转变。
这就是软件 2.0。

软件 1.0 的“经典堆栈”就是我们大家熟悉的--用 Python、C++ 等语言编写。
由程序员写给计算机的明确指令组成。
通过编写每一行代码，程序员控制程序做出期望的行为。

相比之下，软件 2.0 则用更抽象的、而且对人类不友好的语言来编写，比如神经网络的权重。
没有人参与编写这部分代码，因为有太多权重（典型的网络可能有几百万个），直接在权重方面编码有点难（我试过）。

<div align=center><img src="https://s1.ax1x.com/2020/10/19/0xF4cF.png" width="500"></div>

相反，我们的方法是在所需程序的行为上指定一些目标（例如，“满足特定输入输出的数据集”，或者“赢得一盘围棋”），写出一个大致的代码框架（例如神经网络框架），先确定一个包含许多可能实现该功能的程序的集合，然后利用我们所收集到的数据资源在这个集合中搜索出一个最有效的程序。
在神经网络的具体案例中，我们将搜索限制在程序空间的一个连续子集上，在这个子集上，搜索过程可以通过反向传播和随机梯度下降来快速实现。

<div align=center><img src="https://s1.ax1x.com/2020/10/19/0xZRQf.png" width="500"></div>

事实证明，很大一部分现实世界的问题都具有这样的特性：收集数据（或者更一般地说，确定一个理想的行为）比编写明确的程序要容易得多。
在这些情况下，程序员会分成两个团队。
2.0 的程序员手动整理、维护、调整、清理和标注数据集；
每个标注的数据都将为最终的系统做出贡献，因为数据集会通过优化被编译到软件 2.0 的代码中。
同时，1.0 的程序员则负责维护边缘的代码，如工具、分析、可视化、标签界面、基础设施和训练。

## 正在进行的过渡
让我们简单研究一下这种正在进行的过渡的一些具体例子。
在过去几年里，我们看到了这些领域中的改进，我们放弃试图通过编写显式代码来解决一个复杂的问题，而是将代码过渡到 2.0。

**视觉识别**的任务最初是由工程化的特征组成，然后在上面加上一点机器学习算法（例如，SVM）。
从那时起，我们通过获取大型数据集（如 ImageNet）并在卷积神经网络架构的空间中搜索，发现了更强大的视觉特征。
最近，我们在架构的选择上，也不用自己手动选择，而是同样应用搜索算法来确定（[详见](https://arxiv.org/abs/1703.01041)）。

**语音识别**过去涉及大量的预处理、高斯混合物模型和隐藏马尔科夫模型，但[今天几乎完全由神经网络框架组成](https://github.com/syhw/wer_are_we)。
有一句非常相关的、经常被引用的幽默言论，出自于 1985 年，Fred Jelinek，他说：“每当我解雇一个语言学家，我们的语音识别系统的性能就会上升”。

**语音合成**在历史上一直用各种拼接机制来处理，但如今最先进的大型卷积网络（如 [WaveNet](https://deepmind.com/blog/wavenet-launches-google-assistant/)），可以生成原始音频信号。

**机器翻译**通常采用基于短语的统计技术，但基于神经网络的算法正在迅速占据主导地位。
我最喜欢的架构是在弱监督（或[完全无监督](https://arxiv.org/abs/1710.11041)）的环境中训练的[多语言模型](https://arxiv.org/abs/1611.04558)，这些模型可以从任何源语言翻译到任何目标语言。

**游戏**。手动编写规则的下围棋程序有很久的历史了，但基于神经网路的 [AlphaGo Zero](https://deepmind.com/blog/alphago-zero-learning-scratch/)（一个通过棋盘原始状态预测下一步棋的卷积网络）已经成为迄今为止最强的“围棋选手”。
我预计在其他领域也会看到非常类似的结果，比如 [DOTA 2](https://blog.openai.com/more-on-dota-2/)，或者[星际争霸](https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/)等游戏。

**数据库**。人工智能之外的更多传统系统也出现了转型的早期苗头。
例如，“[一个学习索引结构的案例](https://arxiv.org/abs/1712.01208)”用神经网络取代了数据管理系统的核心组件，在速度上比缓存优化的 B-Trees 结构快了 70%，同时节约了一个数量级的内存。

你会注意到，我上面的很多内容都涉及到谷歌所做的工作。
这是因为谷歌目前正处于将传统代码升级到软件 2.0 代码的前沿。
“[一个模型解决所有问题](https://arxiv.org/abs/1706.05137)”描绘了一个草图：各个领域的统治能力将合并成一个一致的，它可以理解整个世界。


---
[返回目录](https://github.com/datugou/Article_Translation/tree/master/LEARNING_data_science)
