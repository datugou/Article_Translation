# Google 翻译的最新进展
_作者：**Isaac Caswell, Bowen Liang**--谷歌研究部软件工程师_  
_原文链接：<https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html>_  
_2020 年 6 月 8 日_  
`Machine Learning` `Machine Translation`

---
机器学习（ML）的进步推动了自动翻译的改进，包括在 2016 年推出的 [GNMT 神经翻译模型](https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html)，使 100 多种语言的翻译质量得到了极大的改善。
尽管如此，除了一些特殊的翻译任务外，即使是最先进的翻译系统，其表现都明显落后于人类。
而且，虽然研究界已经开发出了对西班牙语和德语等高资源语言成功的技术，对这些语言存在大量的训练数据，但在约鲁巴语或马拉雅拉姆语等低资源语言上的表现仍有很多需要改进的地方。
在一些特定研究环境中，许多技术对低资源语言已经展示出了显著的提升（例如，[WMT 评估活动](http://www.statmt.org/wmt20/)），但是这种在较小的、公开数据集上得到的结果，可能很难过渡到大型的、网络爬取的数据集上。。

在这篇文章中，我们分享了最近谷歌翻译在质量方面上取得的一些进展，特别是对于那些低资源的语言，通过综合和扩展各种最近的研究进展，将它们大规模地应用于嘈杂的、网络挖掘的数据中。
这些技术涵盖了对模型架构和训练的改进，对数据集中噪声的改进处理，通过 [M4 建模](https://ai.googleblog.com/2019/10/exploring-massively-multilingual.html)增加了多语言迁移学习，以及单语言数据的使用。
在所有 100 多种语言中的质量改进结果如下图所示，其中 [BLEU 得分](https://en.wikipedia.org/wiki/BLEU)平均增加了 5 分。


<div align=center><h6>谷歌翻译模型自 2006 年成立后的 BLEU 得分。在动画的结尾处强调了自去年实施新技术以来得到的改进。</h6></div>

## 高资源和低资源语言翻译的进步
**混合模型架构**：四年前，我们引入了基于 RNN 的 [GNMT 模型](https://arxiv.org/abs/1609.08144)，该模型对翻译质量有了很大的提高，并使 Google Translate 能够覆盖更多的语言。
根据我们[对模型性能的不同方面进行解耦的工作](https://arxiv.org/abs/1804.09849)，我们替换了原来的 GNMT 系统，而是用一个 [transformer](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html) 编码器和一个 RNN 解码器来训练模型，在 [Lingvo](https://arxiv.org/abs/1902.08295)（TensorFlow 框架）中实现。
[transformer 模型已经被证明在机器翻译方面的表现要比 RNN 模型更有效[(https://arxiv.org/pdf/1706.03762.pdf)，但我们的工作表明，这些质量的提升大部分来自于 transformer 编码器，而 transformer 解码器并没有明显优于 RNN 解码器。
由于 RNN 解码器在推理时间上要快得多，我们在将其进行了各种优化，然后与 transformer 编码器进行耦合。
所得到的混合模型质量更高，训练时更稳定，并且表现出更低的延迟。

**网络抓取**：神经机器翻译（NMT）模型是使用翻译句子和文档的样本进行训练的，这些样本通常是从公共网络上收集的。
与基于短语的机器翻译相比，[NMT 模型的翻译效果对数据质量更加敏感](https://www.aclweb.org/anthology/W18-2709.pdf)。
因此，我们用一个新的数据挖掘机取代了之前的数据收集系统，它更注重精确率而不是召回率，这使得我们可以从公共网络中收集更高质量的训练数据。
此外，我们将 14 种大型语言对的网络爬虫从基于字典的模型换成了基于嵌入的模型，在不损失精度的情况下，平均增加了 29% 收集到的句子数量。

**对数据噪声进行建模**：具有显著噪声的数据不仅是冗余的，而且会降低在其上训练的模型的质量。
为了解决数据噪声问题，我们利用我们在[去噪 NMT 训练](https://www.aclweb.org/anthology/W18-6314/)上取得的成果：首先在噪声数据上训练一个初步的模型，再用干净数据对模型微调，然后用这个模型给每个训练样本进行打分。
然后，我们将翻译模型的训练视为“[课程学习问题](https://arxiv.org/abs/1908.10940)”--模型一开始在全部数据上训练，然后逐渐在较小和较干净的子集上训练。

## 使低资源语言受益的进步
**回译（Back-Translation）**：回译广泛应用于最新的机器翻译系统中，特别适用于那些训练资源匮乏的语言。
该技术使用合成的平行句对数据（原句子与其翻译结果成对）来增强训练过程，其中原语言的句子是由人类编写的，但是它们的翻译则是由神经翻译模型生成的。
通过将回译整合到 Google Translate 中，对于网络上资源较少的语言，我们可以更好地利用单语言文本数据来训练我们的模型。
通常在机器翻译领域中，低资源翻译模型的表现不佳，因此回译的应用对于提高模型输出的流利性尤其有用。

**M4 建模**：[M4](https://ai.googleblog.com/2019/10/exploring-massively-multilingual.html) 是一种对资源匮乏的语言特别有用的技术，它使用单一的大型模型在所有语言和英语之间进行翻译。
这允许大规模的迁移学习。
例如，像意第绪语这样的资源较少的语言，可以和其他相关的日耳曼语（例如德语，荷兰语，丹麦语等）共同训练，从而提升翻译性能；
也可以和其他一百多种语言一起训练，这些语言之间可能存在一些未知的联系，从而为模型提供有用的信号。

## 判断翻译质量
机器翻译系统自动质量评估的一个流行指标是BLEU分数，它基于系统的翻译和人工生成的参考翻译之间的相似性。
通过这些最新的更新，我们看到 BLEU 比之前的 GNMT 模型平均增加了 5 分，其中 50 种低资源的语言达到了+7 BLEU 的平均增益。
这种改进与四年前从基于短语的翻译过渡到 NMT 时所观察到的收益相当。

尽管 BLEU 分数是一个知名的衡量标准，但是众所周知，它对于已经是高质量的系统来说有各种陷阱。
例如，有几项工作证明了 BLEU 分数如何被源语音端或目标语音端的译语效应所偏倚，这种现象使翻译后的文本看起来很笨拙，因为其中包含了源语言的某些属性（如单词顺序）。
因此，我们还对所有新模型进行了人为的评估，这保证了 BLEU 分数的增加确实代表模型翻译质量的提升。

除了改善总体质量外，新模型还改善了‘机器翻译幻觉’的现象，这种现象是在给定无意义的输入时，模型会产生奇怪的“翻译”。
对于在少量数据上训练的模型来说是一个常见的问题，这会影响到许多低资源语言的翻译质量。
例如，当给定泰卢固语字符串“ష ష ష ష ష ష ష ష ష ష ష ష ష ష ష”时，旧模型会产生无意义的输出“Shenzhen Shenzhen Shaw International Airport (SSH)”，似乎有类似的发音，而新模型正确地将其音译为“Sh sh sh sh sh sh sh sh sh sh sh sh sh sh sh sh sh”。

## 结论
虽然这些都是机器翻译令人印象深刻的进步，但我们必须记住，特别是对于低资源语言，自动翻译质量远非完美。
这些模型仍然容易犯典型的机器翻译错误，包括在特定主题类型（or 领域）上表现不佳、混淆语言的不同方言、产生过度文字化的翻译、以及在非正式语言和口语上表现不佳。

尽管如此，通过这次更新，我们很自豪地提供了相对连贯的自动翻译，即使是资源最少的 108 种语言。
我们非常感谢学术界和工业界在机器翻译领域活跃的研究人员所做的工作，使我们能够做到这一点。

## 鸣谢
感谢以下人士，这项工作是建立在他们的基础之上： Tao Yu, Ali Dabirmoghaddam, Klaus Macherey, Pidong Wang, Ye Tian, Jeff Klingner, Jumpei Takeuchi, Yuichiro Sawai, Hideto Kazawa, Apu Shah, Manisha Jain, Keith Stevens, Fangxiaoyu Feng, Chao Tian, John Richardson, Rajat Tibrewal, Orhan Firat, Mia Chen, Ankur Bapna, Naveen Arivazhagan, Dmitry Lepikhin, Wei Wang, Wolfgang Macherey, Katrin Tomanek, Qin Gao, Mengmeng Niu, Macduff Hughes。

---
[返回目录](https://github.com/datugou/Article_Translation/tree/master/LEARNING_data_science)
