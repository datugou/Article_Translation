# 如何解决 90% 的 NLP 问题：分步指南
_作者：[**Emmanuel Ameisen**](https://mlpowered.com/about/)_  
_原文链接：<https://mlpowered.com/posts/how-to-solve-90-nlp/>_  
_2018 年 1 月 24 日_  
`Deep Learnig` `NLP`

---
## 文本数据无处不在
无论你是一家成熟的公司还是致力于推出一项新的服务，你总是可以利用文本数据来验证、改进和扩展产品的功能。
从文本数据中提取意义和学习的科学是一个活跃的研究课题，称为自然语言处理（Natural Language Processing，NLP）。

NLP 每天都在产生新的和令人兴奋的结果，是一个非常大的领域。
然而，在与数百家公司合作后，Insight 团队看到在实际应用中下面这些任务比其他的都要频繁：
- 识别不同的用户/客户群（如预测流失率、终身价值、产品偏好）
- 准确检测并提取不同类别的反馈（正面和负面的评价/意见，对特定属性的提及，如服装尺寸/合身度......）
- 根据意图对文本进行分类（如请求基本帮助、紧急问题）

虽然网上有很多 NLP 论文和教程，但我们发现很难找到如何从根本上**有效**处理这些问题的指南和技巧。

## 本文提供了什么
在每年领导了数百个项目，并获得了全美顶尖团队的建议后，我们写了这篇文章来解释如何构建机器学习解决方案来解决像上面提到的问题。
我们会从**最简单的方法**开始，然后继续介绍更细致的解决方案，比如特征工程、词向量和深度学习。

读完这篇文章，你就会知道如何：
- 收集、准备和检查数据
- 开始建立简单的模型，必要时过渡到深度学习
- 解释和理解你的模型，以确保你确实捕捉到了有用信息，而不是噪音

我们写这篇文章是作为一个分步指南；它也可以作为高效标准方法的高层次概述。

**这篇文章附有一个[交互式笔记本](https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb)，演示和应用所有这些技术。
欢迎运行代码，并跟随我们的脚步!**

## 第一步：收集你的数据
### 数据源示例
每一个机器学习问题都是从数据开始的，比如电子邮件、帖子或微博的列表。
常见的文本信息来源包括：
- 产品评论（在亚马逊，Yelp，和各种 App 商店）
- 用户生成的内容（推特、Facebook 帖子、StackOverflow 问题）
- 故障排除（客户请求、支持票、聊天记录）

#### “社交媒体上的灾难”数据集

在这篇文章中，我们将使用 [Figure Eight](http://www.figure-eight.com/data-for-everyone) 慷慨提供的一个名为“社交媒体上的灾难”数据集，其中:

> 撰稿人查看了一万多条推文，这些推文都是用各种检索词搜索收集的，比如“火烧”、“隔离”和“大恐慌”，然后标注推文是否指的是一个灾难性事件（而不是一个带有这个词的笑话或一个电影评论或一些非灾难性事件）。

我们的任务将是检测哪些推文是关于**灾难性事件**的，而不是一个**不相关的话题**，比如电影。
为什么要这样做呢？
一个潜在的应用是专门通知执法官员关于紧急的紧急情况，而忽略对最近 Adam Sandler 电影的评论。
这项任务的一个特别挑战是，这两个类包含用于查找推文的相同搜索词，因此我们将不得不使用微妙的差异来区分它们。

在这篇文章的其余部分，我们将把关于灾难的推文称为**“灾难”**，而把关于其他任何东西的推文称为**“不相关”**。

### 标签
我们已经标记了数据，所以我们知道哪些推文属于哪些类别。
正如 Richard Socher 所概述的那样，**找到并标记足够的数据**来训练模型，通常会更快、更简单、更便宜，而不是试图优化一个复杂的无监督方法。

## 第二步：清理数据
我们遵循的第一条规则是：“你的模型需要和你的数据一样好。”

数据科学家的关键技能之一就是知道下一步应该在模型还是数据上下功夫。
一个好的经验法则是先看数据，然后清理数据。
一个干净的数据集将使模型能够学习有意义的特征，而不是在不相关的噪声上过度拟合。

下面是一个清理数据的检查表（详见[代码](https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb)）:
- 删除所有不相关的字符，如任何非字母数字字符
- 通过将文本分离成单个单词来[进行分词](https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html)
- 去掉不相关的词，如“@”微博的提及或网址链接
- 将所有字符转换为小写，以便将“hello”、“Hello”和“HELLO”等单词视为相同的字符
- 考虑将拼写错误或交替拼写的单词合并为一个单一的表示方式（如“cool”/“kewl”/“cooool”）
- 考虑[词法化](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)（将“am”、“are”、“is”等词简化为“be”等常见形式）

在遵循这些步骤并检查额外的错误之后，我们就可以开始使用干净的、有标签的数据来训练模型了!

## 第三步：找到一个好的数据表示方法
机器学习模型采用数值作为输入。
例如，在图像上工作的模型会接收一个矩阵，代表每个颜色通道中每个像素的强度。

<div align=center><img src="https://www.mlpowered.com/images/image_matrix.png" width = '700'></div>
<div align=center><h6>以数字矩阵表示的笑脸。</h6></div>

我们的数据集是一个句子的列表，所以为了让我们的算法从数据中提取模式，我们首先需要找到一种我们的算法能够理解的方式来表示它，即作为一个数字列表。

### 独热编码（词袋模型）
对于计算机来说，表示文本的一个自然方法是将每个字符单独编码为一个数字（例如 ASCII）。
如果我们要把这种简单的表示方式输入到分类器中，它就必须只根据我们的数据从头开始学习单词的结构，这对大多数数据集来说是不可能的。
我们需要使用更高层次的方法。

例如，我们可以将数据集中所有独特的单词建立一个**词汇表**，并为词汇表中的每个单词关联一个独特的索引。
然后，每个句子被表示为一个列表，这个列表的长度与我们词汇库中的独特单词的数量一样长。
在这个列表的每个索引处，我们标记出这个词在我们的句子中出现的次数。
这被称为**词袋模型**，因为它是一种完全忽略我们句子中单词顺序的表示方法。
如下图所示。

<div align=center><img src="https://www.mlpowered.com/images/bow.png" width = '700'></div>
<div align=center><h6>将句子表示为一个词袋。左边是句子，右边是表示法。向量中的每个索引都代表一个特定的单词。</h6></div>

### 嵌入的可视化
在“社交媒体的灾难”的例子中，我们的词汇量大约有 20,000 个，这意味着每个句子将被表示为一个长度为 20,000 的向量。
该向量中**大部分是 0**，因为每个句子只包含我们词汇的一个很小的子集。

为了查看我们的嵌入是否捕捉到了与我们的**问题相关的信息**（即这些推文是否是关于灾害的），最好将它们可视化，看看这些类是否看起来很好分离。
由于词汇表通常非常大，在 20,000 个维度上可视化数据是不可能的，所以像 [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) 这样的技术将帮助我们把数据投射到两个维度上。
如下图所示。

<div align=center><img src="https://www.mlpowered.com/images/bow.png" width = '700'></div>
<div align=center><h6>可视化词袋模型嵌入。</h6></div>

两类数据看起来并没有很好的分离，这可能是我们嵌入的整体特征，或者仅仅是我们数据降维之后的特征。
为了看看词袋模型的特征是否真的有用，我们可以基于它们训练一个分类器。

## 步骤4：分类
当第一次处理一个问题时，一般的最佳做法是从能够解决工作的最简单工具开始。
每当涉及到对数据进行分类的问题时，最受欢迎的是方法就是逻辑回归，因其具有很好的通用性和可解释性。
它的训练非常简单，而且结果是可以解释的，因为你可以很容易地从模型中提取最重要的系数。

我们将我们的数据分为用于拟合模型的训练集和测试集，以查看它对未知数据的泛化程度。
训练后，我们得到了 75.4% 的准确率。
不算太寒碜！
然而，即使 75% 的精度足以满足我们的需求，**我们也不应该在没有尝试理解模型的情况下就运送模型**。

## 步骤5：检查
### 混淆矩阵
第一步是了解我们的模型会犯哪些类型的错误，哪种错误是最不可取的。
在我们的例子中，**假阳性**是将不相关的推文分类为灾难，而**假阴性**是将灾难分类为不相关的推文。
如果优先考虑的是对每一个潜在事件做出反应，我们就会希望降低所有误报率。
然而，如果我们资源有限，我们可能会优先考虑降低假阳性率，以减少误报。
将这些信息可视化的一个好方法是使用[混淆矩阵](https://en.wikipedia.org/wiki/Confusion_matrix)，它将我们的模型做出的预测与真实标签进行比较。
理想情况下，矩阵应该是一条从左上到右下的对角线（我们的预测与真实情况完全匹配）。

<div align=center><img src="https://www.mlpowered.com/images/confusion_matrix_bow.png" width = '700'></div>
<div align=center><h6>混乱矩阵（绿色为高比例，蓝色为低比例）。</h6></div>

我们的分类器预测的假阴性比假阳性多（按比例）。
换句话说，我们的模型最常见的错误是将灾害不准确地分类为不相关。
如果假阳性代表了执行的高成本，这种误差可能是我们的分类器的一个很好的情况。

### 解释我们的模型
为了验证我们的模型并解释它的预测，重要的是看它使用哪些词来做决策。
如果我们的数据有偏差，我们的分类器会在样本数据中做出准确的预测，但模型在现实世界中不会有很好的泛化能力。
这里我们绘制了灾难类和不相关类的最重要的词。
使用词袋法和逻辑回归的分类器，为其绘制单词重要性图标很简单，因为我们只需提取模型用于预测的系数并进行排序即可。

<div align=center><img src="https://www.mlpowered.com/images/bow_importance.png" width = '700'></div>
<div align=center><h6>词袋法：单词重要性</h6></div>

我们的分类器正确地挑选了一些模式（广岛 hiroshima，大屠杀 massacre），但显然在一些无意义的词汇上似乎过度拟合（heyoo，x1392）。
现在，我们的词袋模型正在处理一个由不同词汇组成的庞大词汇量，并对所有词汇一视同仁。
然而，其中一些词的出现频率非常高，却只是为我们的预测提供了噪音。
下一步，我们将尝试一种能够考虑到单词频率的句子表示方法，看看能否从我们的数据中接收到更多的信号。

## 第六步：核算词汇结构
### TF-IDF
为了帮助我们的模型更加关注有意义的词，我们可以在词袋模型上使用 (TF-IDF 评分)[https://en.wikipedia.org/wiki/Tf%E2%80%93idf]（Term Frequency，Inverse Document Frequency）。
TF-IDF 根据单词在我们的数据集中的罕见程度来权衡单词，剔除那些过于频繁、只是增加噪音的词。
这里是我们新嵌入的 PCA 投影。

<div align=center><img src="https://www.mlpowered.com/images/pca_tfidf.png" width = '700'></div>
<div align=center><h6>可视化 TF-IDF 嵌入。</h6></div>

我们可以在上面看到，两种颜色之间有了更清晰的区分。
这应该会让我们的分类器更容易将这两个群体分开。
让我们看看这是否会带来更好的性能。
在我们的新嵌入上训练另一个逻辑回归，我们得到了 76.2% 的准确率。

一个非常轻微的改进。
我们的模型是否已经开始拾取更多的重要词汇？
如果我们在防止模型“作弊”的同时得到了更好的结果，那么我们可以真正认为这个模型是一个升级。

<div align=center><img src="https://www.mlpowered.com/images/tfidf_importance.png" width = '700'></div>
<div align=center><h6>TF-IDF：单词重要性</h6></div>

它拾取的词汇看起来更相关了！
虽然我们在测试集上的指标只是略有增加，但我们对我们的模型所使用的词汇更有信心，因此会更放心地将它部署在一个会与客户互动的系统中。

## 第七步：利用语义
### 词向量（Word2Vec）
我们最新的模型成功地选取了高信号词。
但是，如果我们部署这个模型，很有可能会遇到之前在训练集中没有见过的词。
之前的模型将无法准确地对这些推文进行分类，**即使它在训练过程中看到了非常相似的词**。

为了解决这个问题，我们需要捕捉到**词语的语义**，也就是说我们需要理解“好的 good”和“积极的 positive”这样的词语比“杏 apricot”和“洲 continent”在语义上更接近。
我们将用 Word2Vec 来帮助我们捕捉词语意义。

*** 使用预先训练的单词

[Word2Vec](https://arxiv.org/abs/1301.3781) 是一种为单词寻找连续嵌入的技术。
它通过阅读海量的文本，记忆哪些词倾向于出现在类似的语境中，从而学习。
在对足够多的数据进行训练后，它会为词汇中的每个单词生成一个 300 维度的向量，意思相近的单词之间的关系更紧密。

一篇[论文](https://arxiv.org/abs/1301.3781)的作者开源了一个模型，这个模型是在一个非常大的语料库上进行预训练的，我们可以利用这个模型将一些语义的知识加入到我们的模型中。
预训练的向量可以在本帖相关的[资源](https://github.com/hundredblocks/concrete_NLP_tutorial)库中找到。

### 句子级表示
一个快速获得我们分类器的句子嵌入的方法是平均我们句子中所有单词的 Word2Vec 分数。
这和之前的词袋方法一样，但这次我们只丢失了句子的语法，同时保留了一些语义信息。

<div align=center><img src="https://www.mlpowered.com/images/w2v.png" width = '700'></div>
<div align=center><h6>Word2Vec 句子嵌入</h6></div>

下面是我们使用以前的技术对新嵌入的可视化。

<div align=center><img src="https://www.mlpowered.com/images/pca_w2v.png" width = '700'></div>
<div align=center><h6>可视化 Word2Vec 嵌入。</h6></div>

这里的两组颜色看起来更加分离，我们的新嵌入应该可以帮助我们的分类器更好地区分这两个类别。
在第三次训练继续用逻辑回归，我们得到了 77.7% 的准确率，这是我们迄今为止最好的结果。
是时候检查我们的模型了。

### 复杂性/可解释性的权衡
由于我们的嵌入并不像之前的模型那样以每个词一个维度的向量来表示，所以很难看到哪些词与我们的分类最相关。
虽然我们仍然可以访问我们的线性回归的系数，但它们涉及到我们嵌入的 300 个维度，而不是单词的指数。

对于如此低的准确度增益，失去所有可解释性似乎是一个苛刻的权衡。
然而，对于更复杂的模型，我们可以利用**黑盒解释器**，如 [LIME](https://arxiv.org/abs/1602.04938) 来深入了解我们的分类器是如何工作的。

#### LIME

LIME 通过一个[开源包在 Github 上提供](https://github.com/marcotcr/lime)。
一个黑盒解释器允许用户通过扰动输入（在我们的案例中，从句子中删除单词）来解释任何分类器在**一个特定例子**上的决定，并看到预测如何变化。

让我们来看看我们数据集中的几个句子的解释。

<div align=center><img src="https://www.mlpowered.com/images/correct_lime.png" width = '700'></div>
<div align=center><h6>正确的灾难词被选取，以分类为“相关”。</h6></div>

<div align=center><img src="https://www.mlpowered.com/images/incorrect_lime.png" width = '700'></div>
<div align=center><h6>这里，单词对分类的贡献似乎不太明显。</h6></div>

然而，我们没有时间去探索我们数据集中的数千个例子。
我们要做的是在有代表性的测试案例样本上运行 LIME，看看哪些词一直作为强贡献者出现。
使用这种方法，我们可以像之前的模型一样得到单词重要性分数，并验证我们模型的预测。

<div align=center><img src="https://www.mlpowered.com/images/w2v_importance.png" width = '700'></div>
<div align=center><h6>Word2Vec：单词重要性</h6></div>

看起来这个模型能拾取高度相关的词，意味着它似乎能做出可理解的决定。
这些似乎是之前所有模型中最相关的词，因此我们可以更放心地部署到生产中。

## 步骤8：使用端到端方法来利用语法。
我们已经介绍了快速有效的方法来生成紧凑的句子嵌入。
然而，通过省略单词的顺序，我们将丢弃句子的所有语法信息。
如果这些方法不能提供足够的结果，你可以利用更复杂的模型，将整个句子作为输入，并预测标签，而不需要建立一个中间表示。
一个常见的方法是使用 Word2Vec 或类似的方法如 [GloVe](https://nlp.stanford.edu/projects/glove/) 或 [CoVe](https://arxiv.org/abs/1708.00107)，将一个**句子视为多个单词向量的序列**。
这就是我们下面要做的。

<div align=center><img src="https://www.mlpowered.com/images/cnn_architecture.png" width = '700'></div>
<div align=center><h6>一个高效的端到端架构（[来源](https://arxiv.org/abs/1408.5882)）</h6></div>

用于[句子分类的卷积神经网络](https://arxiv.org/abs/1408.5882)的训练速度非常快，并且作为入门级深度学习架构工作得很好。
虽然卷积神经网络（CNN）主要以其在图像数据上的性能而闻名，但它们一直在文本相关任务上提供出色的结果，并且通常比大多数复杂的 NLP 方法（例如 [LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) 和[编码器/解码器](https://www.tensorflow.org/tutorials/seq2seq)架构）更快地进行训练。
该模型保留了单词的顺序，并学习了有价值的信息，即哪些单词序列可以预测我们的目标类。
与之前的模型相反，它可以分辨出“Alex eats plants”和“Plants eat Alex”之间的区别。

训练这个模型并不需要比之前的方法多做很多工作（详见[代码](https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb)），而且给我们提供的模型比之前的模型要好很多，得到了 79.5% 的准确率！
和上面的模型一样，下一步应该是使用我们描述的方法探索和解释预测，以验证它确实是部署给用户的最佳模型。
现在，我觉得你应该可以自己解决这个问题了。

## 最后说明
以下是我们使用的方法的快速总结：
- 从一个快速而简单的模型开始
- 解释其预测
- 了解它正在犯什么样的错误
- 使用这些知识为你的下一步提供信息，无论是在你的数据上工作，还是更复杂的模型

这些方法虽然只应用于一个特定的案例，使用针对理解和利用短文（如推文）的模型，但这些想法可以**广泛适用于各种问题**。
希望对你有所帮助，如果你有意见或问题，欢迎在 [Twitter 上联系作者](https://twitter.com/mlpowered)。

---
[返回目录](https://github.com/datugou/Article_Translation)
